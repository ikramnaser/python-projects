{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Vpq5QrHUrkY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction import text\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"netflixData.csv\")\n",
        "print(data.head())"
      ],
      "metadata": {
        "id": "Jwpvo3MIWZtj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de8c20c8-96e2-4771-e815-665d51dd49e7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                Show Id                          Title  \\\n",
            "0  cc1b6ed9-cf9e-4057-8303-34577fb54477                       (Un)Well   \n",
            "1  e2ef4e91-fb25-42ab-b485-be8e3b23dedb                         #Alive   \n",
            "2  b01b73b7-81f6-47a7-86d8-acb63080d525  #AnneFrank - Parallel Stories   \n",
            "3  b6611af0-f53c-4a08-9ffa-9716dc57eb9c                       #blackAF   \n",
            "4  7f2d4170-bab8-4d75-adc2-197f7124c070               #cats_the_mewvie   \n",
            "\n",
            "                                         Description  \\\n",
            "0  This docuseries takes a deep dive into the luc...   \n",
            "1  As a grisly virus rampages a city, a lone man ...   \n",
            "2  Through her diary, Anne Frank's story is retol...   \n",
            "3  Kenya Barris and his family navigate relations...   \n",
            "4  This pawesome documentary explores how our fel...   \n",
            "\n",
            "                      Director  \\\n",
            "0                          NaN   \n",
            "1                       Cho Il   \n",
            "2  Sabina Fedeli, Anna Migotto   \n",
            "3                          NaN   \n",
            "4             Michael Margolis   \n",
            "\n",
            "                                           Genres  \\\n",
            "0                                      Reality TV   \n",
            "1  Horror Movies, International Movies, Thrillers   \n",
            "2             Documentaries, International Movies   \n",
            "3                                     TV Comedies   \n",
            "4             Documentaries, International Movies   \n",
            "\n",
            "                                                Cast Production Country  \\\n",
            "0                                                NaN      United States   \n",
            "1                           Yoo Ah-in, Park Shin-hye        South Korea   \n",
            "2                        Helen Mirren, Gengher Gatti              Italy   \n",
            "3  Kenya Barris, Rashida Jones, Iman Benson, Genn...      United States   \n",
            "4                                                NaN             Canada   \n",
            "\n",
            "   Release Date Rating  Duration Imdb Score Content Type         Date Added  \n",
            "0        2020.0  TV-MA  1 Season     6.6/10      TV Show                NaN  \n",
            "1        2020.0  TV-MA    99 min     6.2/10        Movie  September 8, 2020  \n",
            "2        2019.0  TV-14    95 min     6.4/10        Movie       July 1, 2020  \n",
            "3        2020.0  TV-MA  1 Season     6.6/10      TV Show                NaN  \n",
            "4        2020.0  TV-14    90 min     5.1/10        Movie   February 5, 2020  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.isnull().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_syz8Lkpi5B6",
        "outputId": "26a546f0-ae2a-4515-b2ad-46469717e2fe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Show Id                  0\n",
            "Title                    0\n",
            "Description              0\n",
            "Director              2064\n",
            "Genres                   0\n",
            "Cast                   530\n",
            "Production Country     559\n",
            "Release Date             3\n",
            "Rating                   4\n",
            "Duration                 3\n",
            "Imdb Score             608\n",
            "Content Type             0\n",
            "Date Added            1335\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.dropna()"
      ],
      "metadata": {
        "id": "WPlqNJJUkVEL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#selectin the columns that we can use to build the algotithm\n",
        "data = data[[\"Title\", \"Description\", \"Content Type\", \"Genres\"]]\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUUyAHZfjxp6",
        "outputId": "67f3d9f9-711b-4c95-cb87-2b9b137e666d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                           Title  \\\n",
            "0                       (Un)Well   \n",
            "1                         #Alive   \n",
            "2  #AnneFrank - Parallel Stories   \n",
            "3                       #blackAF   \n",
            "4               #cats_the_mewvie   \n",
            "\n",
            "                                         Description Content Type  \\\n",
            "0  This docuseries takes a deep dive into the luc...      TV Show   \n",
            "1  As a grisly virus rampages a city, a lone man ...        Movie   \n",
            "2  Through her diary, Anne Frank's story is retol...        Movie   \n",
            "3  Kenya Barris and his family navigate relations...      TV Show   \n",
            "4  This pawesome documentary explores how our fel...        Movie   \n",
            "\n",
            "                                           Genres  \n",
            "0                                      Reality TV  \n",
            "1  Horror Movies, International Movies, Thrillers  \n",
            "2             Documentaries, International Movies  \n",
            "3                                     TV Comedies  \n",
            "4             Documentaries, International Movies  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "nltk.download('stopwords')\n",
        "stemmer = nltk.SnowballStemmer(\"english\")\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "stopword=set(stopwords.words('english'))\n",
        "\n",
        "def clean(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    text = [word for word in text.split(' ') if word not in stopword]\n",
        "    text=\" \".join(text)\n",
        "    text = [stemmer.stem(word) for word in text.split(' ')]\n",
        "    text=\" \".join(text)\n",
        "    return text\n",
        "data[\"Title\"] = data[\"Title\"].apply(clean)\n",
        "\n",
        "print(data.Title.sample(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZREXQbXoEb5",
        "outputId": "64d8c3aa-bf6e-4caf-f18d-049284e25160"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2020                              hello\n",
            "1816         ginni  georgia  afterparti\n",
            "2857        luciano mellera infantiloid\n",
            "5024    magic school bus ride kid space\n",
            "2520         kevin jame never dont give\n",
            "682                              birder\n",
            "4311                   small town crime\n",
            "1787                            gentefi\n",
            "4617          american barbecu showdown\n",
            "222                               agent\n",
            "Name: Title, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using the genres column as feature to recommed similar content\n",
        "feature = data[\"Genres\"].tolist()\n",
        "tfidf = text.TfidfVectorizer(input=feature, stop_words=\"english\")\n",
        "tfidf_matrix = tfidf.fit_transform(feature)\n",
        "similarity = cosine_similarity(tfidf_matrix)"
      ],
      "metadata": {
        "id": "W7hmdxjTodf2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indices = pd.Series(data.index, \n",
        "                    index=data['Title']).drop_duplicates()"
      ],
      "metadata": {
        "id": "RiYwRpaUo-vR"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def netFlix_recommendation(title, similarity = similarity):\n",
        "    index = indices[title]\n",
        "    similarity_scores = list(enumerate(similarity[index]))\n",
        "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
        "    similarity_scores = similarity_scores[0:10]\n",
        "    movieindices = [i[0] for i in similarity_scores]\n",
        "    return data['Title'].iloc[movieindices]\n",
        "\n",
        "print(netFlix_recommendation(\"girlfriend\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACbWfWEVpD99",
        "outputId": "d596bca6-c37e-4aa8-e9d4-2bd338b5cbc9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3                          blackaf\n",
            "285                     washington\n",
            "417                 arrest develop\n",
            "434     astronomi club sketch show\n",
            "451    aunti donna big ol hous fun\n",
            "656                      big mouth\n",
            "752                bojack horseman\n",
            "805                   brew brother\n",
            "935                       champion\n",
            "937                   chappel show\n",
            "Name: Title, dtype: object\n"
          ]
        }
      ]
    }
  ]
}